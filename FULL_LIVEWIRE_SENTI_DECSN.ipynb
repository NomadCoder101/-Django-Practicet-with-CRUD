{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_XdsWx4FuO_k-DKiebCd60-wQji1SsJe",
      "authorship_tag": "ABX9TyOGf8RFhaobhRzOO5MbW4bH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NomadCoder101/-Django-Practicet-with-CRUD/blob/main/FULL_LIVEWIRE_SENTI_DECSN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "M6z6zQ8r_4rK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E_bFKaFz-xGr"
      },
      "outputs": [],
      "source": [
        "# !pip install vaderSentiment\n",
        "# !pip install textblob\n",
        "# !pip install nltk\n",
        "# !pip install pytz\n",
        "# !pip install urllib3\n",
        "# !pip install requests\n",
        "# !pip install beautifulsoup4\n",
        "# !pip install pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas requests beautifulsoup4 textblob nltk"
      ],
      "metadata": {
        "id": "wEUD5aq5zbcj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "moUlQzxeADMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import urllib.parse"
      ],
      "metadata": {
        "id": "7x-BeqS4-_M1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "kTkbMRoM_GCx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycX2W4xs_VZB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FULL LIVEWIRE CODE WITH SENTIMENT AND DECISION v1.1"
      ],
      "metadata": {
        "id": "QOO1OWTGAG4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# from textblob import TextBlob\n",
        "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "# import nltk\n",
        "# from datetime import datetime\n",
        "# import pytz\n",
        "# import urllib.parse\n",
        "\n",
        "# Setup NLTK/VADER\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Paths\n",
        "LEXICON_INPUT = \"/path/to/your/sentiment_data.csv\"  # Replace with your original lexicon file\n",
        "LEXICON_PATH = \"/content/drive/MyDrive/Livewire/stock_lexicon.csv\"\n",
        "LIVEWIRE_OUTPUT = \"/content/drive/MyDrive/Livewire/all_x.csv\"\n",
        "\n",
        "# Step 1: Preprocess Lexicon\n",
        "def preprocess_lexicon(input_file):\n",
        "    print(\"=== Preprocessing Lexicon ===\")\n",
        "    df = pd.read_csv(input_file)\n",
        "    trading_terms = [\n",
        "        \"breakout\", \"crash\", \"bullish\", \"bearish\", \"support\", \"resistance\", \"squeeze\",\n",
        "        \"rally\", \"dip\", \"surge\", \"volatility\", \"trend\", \"buy\", \"sell\", \"market\", \"stock\", \"price\"\n",
        "    ]\n",
        "    df_filtered = df[\n",
        "        df['Item'].str.lower().isin(trading_terms) |\n",
        "        df['Item'].str.contains(\"stock|trade|market|price|buy|sell\", case=False, na=False)\n",
        "    ].copy()\n",
        "\n",
        "    df_filtered.loc[:, 'Aff_Score'] = df_filtered['Aff_Score'].clip(lower=-5, upper=5) / 5\n",
        "    df_filtered.loc[:, 'Neg_Score'] = df_filtered['Neg_Score'].clip(lower=-5, upper=5) / 5\n",
        "    df_filtered.loc[:, 'Sentiment_Score'] = (df_filtered['Aff_Score'] + df_filtered['Neg_Score']) / 2\n",
        "\n",
        "    df_filtered[['Item', 'POS', 'Sentiment_Score']].to_csv(LEXICON_PATH, index=False)\n",
        "    print(f\"Saved {len(df_filtered)} terms to {LEXICON_PATH}\")\n",
        "    return df_filtered\n",
        "\n",
        "# Scraping Functions\n",
        "def scrape_google_news():\n",
        "    print(\"\\n=== Scraping Google News ===\")\n",
        "    google_data = []\n",
        "    url = \"https://news.google.com/rss/search?q=SPY+OR+TSLA&hl=en-US&gl=US&ceid=US:en\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"Google News response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('item')[:10]\n",
        "        print(f\"Found {len(items)} Google News RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.pubDate.text if item.pubDate else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                try:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S %z\")\n",
        "                except ValueError:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S GMT\")\n",
        "                    pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            url = item.link.text if item.link else \"No URL\"\n",
        "            if 'SPY' in title.upper() or 'TSLA' in title.upper() or 'S&P 500' in title.upper():\n",
        "                print(f\"Adding Google News: {title} (Ticker: {'SPY' if 'SPY' in title.upper() or 'S&P 500' in title.upper() else 'TSLA'})\")\n",
        "                google_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'Google News',\n",
        "                    'ticker': 'SPY' if 'SPY' in title.upper() or 'S&P 500' in title.upper() else 'TSLA',\n",
        "                    'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(google_data)} Google News row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Google News scrape failed: {e}\")\n",
        "    return pd.DataFrame(google_data)\n",
        "\n",
        "def scrape_yahoo_finance():\n",
        "    print(\"\\n=== Scraping Yahoo Finance ===\")\n",
        "    yahoo_data = []\n",
        "    for ticker, url in [(\"SPY\", \"https://finance.yahoo.com/rss/headline?s=SPY\"), (\"TSLA\", \"https://finance.yahoo.com/rss/headline?s=TSLA\")]:\n",
        "        try:\n",
        "            response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "            print(f\"Yahoo {ticker} response status: {response.status_code}\")\n",
        "            soup = BeautifulSoup(response.text, 'xml')\n",
        "            items = soup.find_all('item')[:5]\n",
        "            print(f\"Found {len(items)} Yahoo {ticker} articles\")\n",
        "            for item in items:\n",
        "                title = item.title.text if item.title else \"No title\"\n",
        "                pub_date = item.pubDate.text if item.pubDate else datetime.now(pytz.utc)\n",
        "                if isinstance(pub_date, str):\n",
        "                    try:\n",
        "                        pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S %z\")\n",
        "                    except ValueError:\n",
        "                        pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S GMT\")\n",
        "                        pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
        "                pdt = pytz.timezone('America/Los_Angeles')\n",
        "                timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "                url = item.link.text if item.link else \"No URL\"\n",
        "                if ticker in title.upper() or ('S&P 500' in title.upper() and ticker == 'SPY'):\n",
        "                    print(f\"Adding Yahoo {ticker}: {title}\")\n",
        "                    yahoo_data.append({\n",
        "                        'timestamp': timestamp, 'source': 'Yahoo Finance',\n",
        "                        'ticker': ticker, 'headline': title, 'url': url\n",
        "                    })\n",
        "            print(f\"Scraped {len(yahoo_data)} Yahoo {ticker} row(s)\")\n",
        "        except Exception as e:\n",
        "            print(f\"Yahoo {ticker} scrape failed: {e}\")\n",
        "    return pd.DataFrame(yahoo_data)\n",
        "\n",
        "def scrape_cnbc_news():\n",
        "    print(\"\\n=== Scraping CNBC ===\")\n",
        "    cnbc_data = []\n",
        "    url = \"https://www.cnbc.com/id/100003114/device/rss/rss.html\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"CNBC response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('item')[:10]\n",
        "        print(f\"Found {len(items)} CNBC RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.pubDate.text if item.pubDate else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                try:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S %z\")\n",
        "                except ValueError:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S GMT\")\n",
        "                    pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            url = item.link.text if item.link else \"No URL\"\n",
        "            description = item.description.text if item.description else \"\"\n",
        "            if any(x in (title.upper() + description.upper()) for x in ['SPY', 'TSLA', 'S&P 500', 'TESLA']):\n",
        "                ticker = 'SPY' if 'SPY' in (title.upper() + description.upper()) or 'S&P 500' in (title.upper() + description.upper()) else 'TSLA'\n",
        "                print(f\"Adding CNBC: {title} (Ticker: {ticker})\")\n",
        "                cnbc_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'CNBC',\n",
        "                    'ticker': ticker, 'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(cnbc_data)} CNBC row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"CNBC scrape failed: {e}\")\n",
        "    return pd.DataFrame(cnbc_data)\n",
        "\n",
        "def scrape_seeking_alpha_news():\n",
        "    print(\"\\n=== Scraping Seeking Alpha ===\")\n",
        "    sa_data = []\n",
        "    url = \"https://seekingalpha.com/market_currents.xml\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"Seeking Alpha response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('item')[:10]\n",
        "        print(f\"Found {len(items)} Seeking Alpha RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.pubDate.text if item.pubDate else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                try:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S %z\")\n",
        "                except ValueError:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S GMT\")\n",
        "                    pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            url = item.link.text if item.link else \"No URL\"\n",
        "            description = item.description.text if item.description else \"\"\n",
        "            if any(x in (title.upper() + description.upper()) for x in ['SPY', 'TSLA', 'S&P 500', 'TESLA']):\n",
        "                ticker = 'SPY' if 'SPY' in (title.upper() + description.upper()) or 'S&P 500' in (title.upper() + description.upper()) else 'TSLA'\n",
        "                print(f\"Adding Seeking Alpha: {title} (Ticker: {ticker})\")\n",
        "                sa_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'Seeking Alpha',\n",
        "                    'ticker': ticker, 'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(sa_data)} Seeking Alpha row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Seeking Alpha scrape failed: {e}\")\n",
        "    return pd.DataFrame(sa_data)\n",
        "\n",
        "def scrape_nyt_business_news():\n",
        "    print(\"\\n=== Scraping NYT Business ===\")\n",
        "    nyt_data = []\n",
        "    url = \"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"NYT Business response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('item')[:10]\n",
        "        print(f\"Found {len(items)} NYT Business RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.pubDate.text if item.pubDate else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                try:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S %z\")\n",
        "                except ValueError:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "                    pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            url = item.link.text if item.link else \"No URL\"\n",
        "            description = item.description.text if item.description else \"\"\n",
        "            if any(x in (title.upper() + description.upper()) for x in ['SPY', 'TSLA', 'S&P 500', 'TESLA']):\n",
        "                ticker = 'SPY' if 'SPY' in (title.upper() + description.upper()) or 'S&P 500' in (title.upper() + description.upper()) else 'TSLA'\n",
        "                print(f\"Adding NYT Business: {title} (Ticker: {ticker})\")\n",
        "                nyt_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'NYT Business',\n",
        "                    'ticker': ticker, 'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(nyt_data)} NYT Business row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"NYT Business scrape failed: {e}\")\n",
        "    return pd.DataFrame(nyt_data)\n",
        "\n",
        "def scrape_wapo_business_news():\n",
        "    print(\"\\n=== Scraping WaPo Business ===\")\n",
        "    wapo_data = []\n",
        "    url = \"https://feeds.washingtonpost.com/rss/business?itid=lk_inline_manual_32\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"WaPo Business response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('item')[:10]\n",
        "        print(f\"Found {len(items)} WaPo Business RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.pubDate.text if item.pubDate else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                try:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%a, %d %b %Y %H:%M:%S %z\")\n",
        "                except ValueError:\n",
        "                    pub_date = datetime.strptime(pub_date, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "                    pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            url = item.link.text if item.link else \"No URL\"\n",
        "            description = item.description.text if item.description else \"\"\n",
        "            if any(x in (title.upper() + description.upper()) for x in ['SPY', 'TSLA', 'S&P 500', 'TESLA']):\n",
        "                ticker = 'SPY' if 'SPY' in (title.upper() + description.upper()) or 'S&P 500' in (title.upper() + description.upper()) else 'TSLA'\n",
        "                print(f\"Adding WaPo Business: {title} (Ticker: {ticker})\")\n",
        "                wapo_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'WaPo Business',\n",
        "                    'ticker': ticker, 'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(wapo_data)} WaPo Business row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"WaPo Business scrape failed: {e}\")\n",
        "    return pd.DataFrame(wapo_data)\n",
        "\n",
        "def scrape_google_alerts_tsla():\n",
        "    print(\"\\n=== Scraping Google Alerts (TSLA) ===\")\n",
        "    tsla_data = []\n",
        "    url = \"https://www.google.com/alerts/feeds/08226079376422840598/3686544122646381017\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"Google Alerts TSLA response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('entry')[:10]\n",
        "        print(f\"Found {len(items)} Google Alerts TSLA RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.published.text if item.published else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                pub_date = datetime.strptime(pub_date, \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            link = item.link.get('href') if item.link and item.link.get('href') else \"No URL\"\n",
        "            if link.startswith(\"https://www.google.com/url?\"):\n",
        "                parsed_url = urllib.parse.urlparse(link)\n",
        "                query = urllib.parse.parse_qs(parsed_url.query)\n",
        "                url = query.get('url', [link])[0]\n",
        "            else:\n",
        "                url = link\n",
        "            if 'TSLA' in title.upper() or 'TESLA' in title.upper():\n",
        "                print(f\"Adding Google Alerts TSLA: {title}\")\n",
        "                tsla_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'Google Alerts',\n",
        "                    'ticker': 'TSLA', 'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(tsla_data)} Google Alerts TSLA row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Google Alerts TSLA scrape failed: {e}\")\n",
        "    return pd.DataFrame(tsla_data)\n",
        "\n",
        "def scrape_google_alerts_spy():\n",
        "    print(\"\\n=== Scraping Google Alerts (SPY) ===\")\n",
        "    spy_data = []\n",
        "    url = \"https://www.google.com/alerts/feeds/08226079376422840598/9371419328304257641\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        print(f\"Google Alerts SPY response status: {response.status_code}\")\n",
        "        soup = BeautifulSoup(response.text, 'xml')\n",
        "        items = soup.find_all('entry')[:10]\n",
        "        print(f\"Found {len(items)} Google Alerts SPY RSS items\")\n",
        "        for item in items:\n",
        "            title = item.title.text if item.title else \"No title\"\n",
        "            pub_date = item.published.text if item.published else datetime.now(pytz.utc)\n",
        "            if isinstance(pub_date, str):\n",
        "                pub_date = datetime.strptime(pub_date, \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=pytz.UTC)\n",
        "            pdt = pytz.timezone('America/Los_Angeles')\n",
        "            timestamp = pub_date.astimezone(pdt).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            link = item.link.get('href') if item.link and item.link.get('href') else \"No URL\"\n",
        "            if link.startswith(\"https://www.google.com/url?\"):\n",
        "                parsed_url = urllib.parse.urlparse(link)\n",
        "                query = urllib.parse.parse_qs(parsed_url.query)\n",
        "                url = query.get('url', [link])[0]\n",
        "            else:\n",
        "                url = link\n",
        "            if 'SPY' in title.upper() or 'S&P 500' in title.upper() or 'SPDR S&P 500' in title.upper():\n",
        "                print(f\"Adding Google Alerts SPY: {title}\")\n",
        "                spy_data.append({\n",
        "                    'timestamp': timestamp, 'source': 'Google Alerts',\n",
        "                    'ticker': 'SPY', 'headline': title, 'url': url\n",
        "                })\n",
        "        print(f\"Scraped {len(spy_data)} Google Alerts SPY row(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Google Alerts SPY scrape failed: {e}\")\n",
        "    return pd.DataFrame(spy_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a0e35f-84b1-47ea-c8c8-d71b3283259b",
        "id": "dtqqHn0l0jUb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "LIVEWIRE_OUTPUT = \"/content/drive/MyDrive/Livewire/all_x.csv\"\n",
        "LEXICON_PATH = \"/content/drive/MyDrive/Livewire/stock_lexicon.csv\"\n",
        "\n",
        "def process_livewire(lexicon_df):\n",
        "    print(\"\\n=== Processing Livewire Data ===\")\n",
        "    scrape_functions = [\n",
        "        scrape_google_news, scrape_yahoo_finance, scrape_cnbc_news,\n",
        "        scrape_seeking_alpha_news, scrape_nyt_business_news, scrape_wapo_business_news,\n",
        "        scrape_google_alerts_tsla, scrape_google_alerts_spy\n",
        "    ]\n",
        "    all_dfs = []\n",
        "    for func in scrape_functions:\n",
        "        try:\n",
        "            df = func()\n",
        "            print(f\"{func.__name__} returned {len(df)} rows\")\n",
        "            if not df.empty:\n",
        "                all_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"{func.__name__} failed: {e}\")\n",
        "\n",
        "    all_df = pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame(\n",
        "        columns=['timestamp', 'source', 'ticker', 'headline', 'url']\n",
        "    )\n",
        "    print(f\"Combined rows before dedupe: {len(all_df)}\")\n",
        "\n",
        "    if all_df.empty:\n",
        "        print(\"No data scraped—returning empty DataFrame\")\n",
        "        return all_df\n",
        "\n",
        "    try:\n",
        "        all_df['headline'] = all_df['headline'].str.replace(r'<[^>]+>|[^\\w\\s]', '', regex=True).str.strip()\n",
        "        print(\"Duplicate check (pre-dedupe):\")\n",
        "        dups = all_df[all_df.duplicated(subset=['headline'], keep=False)]\n",
        "        if not dups.empty:\n",
        "            print(dups[['headline', 'url']].to_string(index=False))\n",
        "        else:\n",
        "            print(\"No duplicates found\")\n",
        "        deduped_df = all_df.drop_duplicates(subset=['headline'], keep='first').reset_index(drop=True)  # Initial dedupe\n",
        "        print(f\"Combined rows after dedupe: {len(deduped_df)}\")\n",
        "\n",
        "        def get_sentiment(headline, lexicon_df):\n",
        "            blob = TextBlob(headline)\n",
        "            vader_score = sid.polarity_scores(headline)['compound']\n",
        "            base_score = (blob.sentiment.polarity + vader_score) / 2\n",
        "            lexicon_score = 0\n",
        "            matches = 0\n",
        "            for _, row in lexicon_df.iterrows():\n",
        "                if row['Item'] in headline.lower():\n",
        "                    lexicon_score += row['Sentiment_Score']\n",
        "                    matches += 1\n",
        "            final_score = lexicon_score / matches if matches > 0 else base_score\n",
        "            negative_keywords = ['fallout', 'red', 'drop', 'decline', 'crash', 'fall', 'plunge', 'challenges', 'downgrade', 'slide']\n",
        "            positive_keywords = ['buy', 'surge', 'rally', 'up', 'bullish']\n",
        "            pos_matches = any(kw in headline.lower() for kw in positive_keywords)\n",
        "            neg_matches = any(kw in headline.lower() for kw in negative_keywords)\n",
        "            if pos_matches:\n",
        "                final_score = max(final_score, 0.3)\n",
        "            elif neg_matches:\n",
        "                final_score = min(final_score, -0.3)\n",
        "            else:\n",
        "                final_score = 0 if abs(final_score) < 0.1 else final_score\n",
        "            sentiment = ('tense' if final_score < 0 and any(kw in headline.lower() for kw in ['crash', 'fall', 'plunge']) else\n",
        "                        'shaky' if final_score < 0 else\n",
        "                        'neutral' if final_score <= 0.5 else 'bullish')\n",
        "            return sentiment, final_score\n",
        "\n",
        "        deduped_df[['sentiment', 'sentiment_score']] = deduped_df['headline'].apply(lambda x: pd.Series(get_sentiment(x, lexicon_df)))\n",
        "        deduped_df['timestamp'] = pd.to_datetime(deduped_df['timestamp'], errors='coerce')\n",
        "        sorted_df = deduped_df.dropna(subset=['timestamp']).sort_values('timestamp', ascending=False)\n",
        "        final_df = sorted_df.drop_duplicates(subset=['headline'], keep='first').head(15)  # Final dedupe after sort\n",
        "\n",
        "        # Debug: Check for duplicates in final_df\n",
        "        final_dups = final_df[final_df.duplicated(subset=['headline'], keep=False)]\n",
        "        if not final_dups.empty:\n",
        "            print(\"WARNING: Duplicates found in final output:\")\n",
        "            print(final_dups[['headline', 'url']].to_string(index=False))\n",
        "        else:\n",
        "            print(\"No duplicates in final output.\")\n",
        "\n",
        "        print(\"Combined sample (top 15):\")\n",
        "        print(final_df.to_string(index=False))\n",
        "        final_df.to_csv(LIVEWIRE_OUTPUT, index=False)\n",
        "        print(f\"Saved {len(final_df)} rows to {LIVEWIRE_OUTPUT}\")\n",
        "        return final_df\n",
        "    except Exception as e:\n",
        "        print(f\"Processing failed: {e}\")\n",
        "        return all_df\n",
        "\n",
        "def make_decision(sentiment_score, capital=10000):\n",
        "    dp = max(min(sentiment_score * 20, 10), -10)\n",
        "    decision = \"Buy\" if dp > 3 else \"Sell\" if dp < -3 else \"Hold\"  # Adjusted thresholds\n",
        "    net = 0.035 * capital if decision == \"Buy\" else -0.035 * capital if decision == \"Sell\" else 0\n",
        "    return decision, dp, net\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Starting Full Livewire Pipeline ===\")\n",
        "    lexicon_df = pd.read_csv(LEXICON_PATH)\n",
        "    print(f\"Loaded lexicon with {len(lexicon_df)} terms\")\n",
        "    livewire_df = process_livewire(lexicon_df)\n",
        "    print(\"\\n=== Final Results with Algo Decisions ===\")\n",
        "    if livewire_df is None or livewire_df.empty:\n",
        "        print(\"No data to process—skipping decisions\")\n",
        "    else:\n",
        "        for _, row in livewire_df.iterrows():\n",
        "            decision, dp, net = make_decision(row['sentiment_score'])\n",
        "            print(f\"Headline: {row['headline'][:50]}... | Sentiment: {row['sentiment']} | Score: {row['sentiment_score']:.2f} | dp: {dp} | Decision: {decision} | Net: {net}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVSM3x-gf8jN",
        "outputId": "a534d6f5-3962-42e9-ae5d-1d910c396529"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Starting Full Livewire Pipeline ===\n",
            "Loaded lexicon with 612 terms\n",
            "\n",
            "=== Processing Livewire Data ===\n",
            "\n",
            "=== Scraping Google News ===\n",
            "Google News response status: 200\n",
            "Found 10 Google News RSS items\n",
            "Adding Google News: Elon tells Tesla employees not to sell TSLA stocks as board and execs are dumping - Electrek.co (Ticker: TSLA)\n",
            "Adding Google News: Netanyahu’s targeting of an Israeli spy chief and the attorney general - Al Jazeera English (Ticker: SPY)\n",
            "Adding Google News: Elon Musk's Potential Margin Call - The Facts (NASDAQ:TSLA) - Seeking Alpha (Ticker: TSLA)\n",
            "Adding Google News: Why Tesla Inc. (TSLA) Stock Crashed On Monday - Yahoo Finance (Ticker: TSLA)\n",
            "Adding Google News: Google’s $32B Deal and a Silicon Valley Spy Scandal! - The Information (Ticker: SPY)\n",
            "Adding Google News: Russian journalist target by Kremlin-backed spy ring speaks out - WBUR News (Ticker: SPY)\n",
            "Adding Google News: Arsonist, Killer, Saboteur, Spy: While Trump Courts Him, Putin Is Escalating Russia’s Hybrid War Against the West - Foreign Affairs Magazine (Ticker: SPY)\n",
            "Adding Google News: Tesla stock price: 3 possible reasons why TSLA is sinking again today - Fast Company (Ticker: TSLA)\n",
            "Adding Google News: Could Donald Trump imperil the Five Eyes spy pact? - The Economist (Ticker: SPY)\n",
            "Scraped 9 Google News row(s)\n",
            "scrape_google_news returned 9 rows\n",
            "\n",
            "=== Scraping Yahoo Finance ===\n",
            "Yahoo SPY response status: 200\n",
            "Found 5 Yahoo SPY articles\n",
            "Adding Yahoo SPY: Stock market today: S&P 500 snaps 4-week losing streak in latest volatile week on Wall Street\n",
            "Scraped 1 Yahoo SPY row(s)\n",
            "Yahoo TSLA response status: 200\n",
            "Found 5 Yahoo TSLA articles\n",
            "Scraped 1 Yahoo TSLA row(s)\n",
            "scrape_yahoo_finance returned 1 rows\n",
            "\n",
            "=== Scraping CNBC ===\n",
            "CNBC response status: 200\n",
            "Found 10 CNBC RSS items\n",
            "Adding CNBC: Elon Musk tells Tesla employees 'hang onto your stock,' urges vandals to 'stop being psycho' (Ticker: TSLA)\n",
            "Adding CNBC: Tesla owners are trading in their EVs at record levels, Edmunds says (Ticker: TSLA)\n",
            "Scraped 2 CNBC row(s)\n",
            "scrape_cnbc_news returned 2 rows\n",
            "\n",
            "=== Scraping Seeking Alpha ===\n",
            "Seeking Alpha response status: 200\n",
            "Found 7 Seeking Alpha RSS items\n",
            "Scraped 0 Seeking Alpha row(s)\n",
            "scrape_seeking_alpha_news returned 0 rows\n",
            "\n",
            "=== Scraping NYT Business ===\n",
            "NYT Business response status: 200\n",
            "Found 10 NYT Business RSS items\n",
            "Scraped 0 NYT Business row(s)\n",
            "scrape_nyt_business_news returned 0 rows\n",
            "\n",
            "=== Scraping WaPo Business ===\n",
            "WaPo Business response status: 200\n",
            "Found 8 WaPo Business RSS items\n",
            "Adding WaPo Business: Tesla owners are trading in cars at record rates amid Musk backlash (Ticker: TSLA)\n",
            "Scraped 1 WaPo Business row(s)\n",
            "scrape_wapo_business_news returned 1 rows\n",
            "\n",
            "=== Scraping Google Alerts (TSLA) ===\n",
            "Google Alerts TSLA response status: 200\n",
            "Found 10 Google Alerts TSLA RSS items\n",
            "Adding Google Alerts TSLA: Technical Analysis of Stocks: SPY / QQQ / NVDA / <b>TSLA</b> / AMD / PLTR / MU / SOFI / INTC\n",
            "Adding Google Alerts TSLA: FinTwitter: &quot;$<b>TSLA</b> - MUSK: TESLA TO BUILD 5,000 OPTIMUS ROBOTS IN 2025, TELLS ...\n",
            "Adding Google Alerts TSLA: Tesla (<b>TSLA</b>) Faces Market Challenges as Mizuho Adjusts Price Target Amid AI Growth\n",
            "Adding Google Alerts TSLA: Tesla (<b>TSLA</b>) Faces Market Challenges as Mizuho Adjusts Price Target Amid AI Growth\n",
            "Adding Google Alerts TSLA: This Analyst Thinks Tesla Stock Is Oversold. Should You Buy <b>TSLA</b> Now? - Barchart.com\n",
            "Adding Google Alerts TSLA: This Analyst Thinks Tesla Stock Is Oversold. Should You Buy <b>TSLA</b> Now?\n",
            "Adding Google Alerts TSLA: Rabbi Killed by Traffic After His Tesla Has “Veered” Crash - flyingpenguin\n",
            "Adding Google Alerts TSLA: Elon Musk talks up Tesla&#39;s future at employee all-hands meeting - YouTube\n",
            "Adding Google Alerts TSLA: <b>TSLA</b> &#39;Light Years&#39; Ahead of Competition, A.I. Key to Unlocking Upside | Schwab Network\n",
            "Adding Google Alerts TSLA: Trump has suggested sending Tesla, $<b>TSLA</b>, vandals to El Salvador prisons - Threads\n",
            "Scraped 10 Google Alerts TSLA row(s)\n",
            "scrape_google_alerts_tsla returned 10 rows\n",
            "\n",
            "=== Scraping Google Alerts (SPY) ===\n",
            "Google Alerts SPY response status: 200\n",
            "Found 10 Google Alerts SPY RSS items\n",
            "Adding Google Alerts SPY: <b>SPY</b> Versus Buffett&#39;s Berkshire: Dealing With Things You Can&#39;t Control - Seeking Alpha\n",
            "Adding Google Alerts SPY: How To Trade <b>SPY</b> Ahead Of Triple Witching? - <b>SPDR S&amp;P 500</b> (ARCA:<b>SPY</b>) - Benzinga\n",
            "Adding Google Alerts SPY: Mirae Asset Global Investments Co., Ltd.&#39;s <b>SPDR S&amp;P 500 ETF Trust</b>(<b>SPY</b>) Holding History\n",
            "Scraped 3 Google Alerts SPY row(s)\n",
            "scrape_google_alerts_spy returned 3 rows\n",
            "Combined rows before dedupe: 26\n",
            "Duplicate check (pre-dedupe):\n",
            "                                                                        headline                                                                                                                          url\n",
            "Tesla TSLA Faces Market Challenges as Mizuho Adjusts Price Target Amid AI Growth                                             https://finance.yahoo.com/news/tesla-tsla-faces-market-challenges-204646502.html\n",
            "Tesla TSLA Faces Market Challenges as Mizuho Adjusts Price Target Amid AI Growth https://www.insidermonkey.com/blog/tesla-tsla-faces-market-challenges-as-mizuho-adjusts-price-target-amid-ai-growth-1488759/\n",
            "Combined rows after dedupe: 25\n",
            "No duplicates in final output.\n",
            "Combined sample (top 15):\n",
            "          timestamp        source ticker                                                                                   headline                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        url sentiment  sentiment_score\n",
            "2025-03-21 15:03:18          CNBC   TSLA    Elon Musk tells Tesla employees hang onto your stock urges vandals to stop being psycho                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     https://www.cnbc.com/2025/03/21/elon-musk-tells-tesla-employees-hang-onto-your-stock-in-all-hands.html   neutral         0.101229\n",
            "2025-03-21 14:59:58 Google Alerts   TSLA               Technical Analysis of Stocks SPY  QQQ  NVDA  TSLA  AMD  PLTR  MU  SOFI  INTC                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                https://www.youtube.com/watch?v=sMmczPFZVGY   neutral         0.101229\n",
            "2025-03-21 14:08:07 Google Alerts   TSLA                 FinTwitter quotTSLA  MUSK TESLA TO BUILD 5000 OPTIMUS ROBOTS IN 2025 TELLS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         https://bsky.app/profile/fintwitter.bsky.social/post/3lkvhcs7am42u   neutral         0.000000\n",
            "2025-03-21 13:58:36 Google Alerts   TSLA           Tesla TSLA Faces Market Challenges as Mizuho Adjusts Price Target Amid AI Growth                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           https://finance.yahoo.com/news/tesla-tsla-faces-market-challenges-204646502.html     shaky        -0.300000\n",
            "2025-03-21 13:17:47 Google Alerts   TSLA           This Analyst Thinks Tesla Stock Is Oversold Should You Buy TSLA Now  Barchartcom                                                                                                                                                                                                                                                                                                                                                                                                                                                                           https://www.barchart.com/story/news/31525875/this-analyst-thinks-tesla-stock-is-oversold-should-you-buy-tsla-now   neutral         0.300000\n",
            "2025-03-21 13:13:48 Google Alerts   TSLA                        This Analyst Thinks Tesla Stock Is Oversold Should You Buy TSLA Now                                                                                                                                                                                                                                                                                                                                                                                                                                                                     https://www.tamabentoncoop.com/news/story/31525877/this-analyst-thinks-tesla-stock-is-oversold-should-you-buy-tsla-now   neutral         0.300000\n",
            "2025-03-21 13:13:03   Google News    SPY  Netanyahus targeting of an Israeli spy chief and the attorney general  Al Jazeera English https://news.google.com/rss/articles/CBMivwFBVV95cUxNQkYtMW1Ydy1Ca09nTWU4LTRwN1ViMVREeHRWUHFITnVyR20wTnpyMGpXc1Q1WDdvVkJTUmhmdE5XcERUcTFfcmptYVp3N3hYZ0wzaVI5T29aX01OMkh5Y0tIYjdMd2VSc3ppVEN1b2tMelVueUgwUVJJMGg4RzFRUHVBY2UtdU1KbFgtRURVN0tOenhLVUEtNjZJWjJPWVVEUU9NQlJObFF6Z3dMbHZhTE5RalM1Ujg5VHVkeWYxNNIBxAFBVV95cUxNYWNVQ0FVVFEwakRJbE5KSXRoZF80eXItQ1ZFSDU1OWkxNV9QTmxmOE5xQnZmWVo2TVh5U3Z2eVlsRGx6dU1rampDR1hkUU84LXhGUEE3WVp3WVlFbk42MVdpNFhhR3NIODlkMktfRFhNMmxqY3RwSTNMeGRlc0JnU2lDSlVZN3lRQXJuZ0kwaFEyV3hsaVplUld6c2JoSW9OUW5pQ2VvVk5iT29mRUFoUEtsZG1DdF9RRnBUeXBLMmp2Ym9L?oc=5   neutral         0.000000\n",
            "2025-03-21 13:04:39 WaPo Business   TSLA                        Tesla owners are trading in cars at record rates amid Musk backlash                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              https://www.washingtonpost.com/business/2025/03/21/tesla-trade-ins-elon-musk/   neutral         0.000000\n",
            "2025-03-21 13:00:54 Google Alerts   TSLA                    Rabbi Killed by Traffic After His Tesla Has Veered Crash  flyingpenguin                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     https://www.flyingpenguin.com/?p=68689     tense        -0.300000\n",
            "2025-03-21 13:00:32 Yahoo Finance    SPY Stock market today SP 500 snaps 4week losing streak in latest volatile week on Wall Street                                                                                                                                                                                                                                                                                                                                                                                                                                   https://finance.yahoo.com/news/live/stock-market-today-sp-500-snaps-4-week-losing-streak-in-latest-volatile-week-on-wall-street-200032297.html?.tsrc=rss   neutral         0.000000\n",
            "2025-03-21 12:58:19 Google Alerts   TSLA                   Elon Musk talks up Tesla39s future at employee allhands meeting  YouTube                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                https://www.youtube.com/watch?v=fOO-eWGU1xU   neutral         0.300000\n",
            "2025-03-21 12:51:59 Google Alerts   TSLA       TSLA 39Light Years39 Ahead of Competition AI Key to Unlocking Upside  Schwab Network                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          https://schwabnetwork.com/video/tsla-light-years-ahead-of-competition-a-i-key-to-unlocking-upside   neutral         0.300000\n",
            "2025-03-21 12:47:29 Google Alerts   TSLA             Trump has suggested sending Tesla TSLA vandals to El Salvador prisons  Threads                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    https://www.threads.net/@unusualwhales/post/DHeHaEkPAWP   neutral         0.000000\n",
            "2025-03-21 11:14:00   Google News    SPY                         Googles 32B Deal and a Silicon Valley Spy Scandal  The Information                                                                                                                                                                                                                                                                                                                                                 https://news.google.com/rss/articles/CBMiiwFBVV95cUxOVUhDRmkxMlliYnZ4VFZhUFhtWnUxeXd5SktLbFVpT20zTng0eU4yc3c5X2hxTmttd1ZtY25pNTlzRVViZmdKWGt1M2hodDdKS25MbWp5NE9ZWEVWSXFjUXVYM3dJUzJOOWpsYjhwUllUUDlmT0RhbldsR0NTMDdOTlpfQl96a3Y2WUR3?oc=5     shaky        -0.220200\n",
            "2025-03-21 08:45:46   Google News    SPY                  Russian journalist target by Kremlinbacked spy ring speaks out  WBUR News                                                                                                                                                                                                                                                                                                                                                                         https://news.google.com/rss/articles/CBMiekFVX3lxTE45ZDRJMUF4RUVFQWVmeE01OTlKbFBEV2xrdUVmd2pfYU5kVVRwX0s3ek5Qek5ucDFWUTIwTmhrMWlrM0xTa0VRbUlzTjEwenFEMEdrZng1TzZvd2s3QWRpdGpWQmxUeXhnXzU5SWRta0JYaWNXVVQzaXlR?oc=5   neutral         0.000000\n",
            "Saved 15 rows to /content/drive/MyDrive/Livewire/all_x.csv\n",
            "\n",
            "=== Final Results with Algo Decisions ===\n",
            "Headline: Elon Musk tells Tesla employees hang onto your sto... | Sentiment: neutral | Score: 0.10 | dp: 2.024574074269752 | Decision: Hold | Net: 0\n",
            "Headline: Technical Analysis of Stocks SPY  QQQ  NVDA  TSLA ... | Sentiment: neutral | Score: 0.10 | dp: 2.024574074269752 | Decision: Hold | Net: 0\n",
            "Headline: FinTwitter quotTSLA  MUSK TESLA TO BUILD 5000 OPTI... | Sentiment: neutral | Score: 0.00 | dp: 0.0 | Decision: Hold | Net: 0\n",
            "Headline: Tesla TSLA Faces Market Challenges as Mizuho Adjus... | Sentiment: shaky | Score: -0.30 | dp: -6.0 | Decision: Sell | Net: -350.00000000000006\n",
            "Headline: This Analyst Thinks Tesla Stock Is Oversold Should... | Sentiment: neutral | Score: 0.30 | dp: 6.0 | Decision: Buy | Net: 350.00000000000006\n",
            "Headline: This Analyst Thinks Tesla Stock Is Oversold Should... | Sentiment: neutral | Score: 0.30 | dp: 6.0 | Decision: Buy | Net: 350.00000000000006\n",
            "Headline: Netanyahus targeting of an Israeli spy chief and t... | Sentiment: neutral | Score: 0.00 | dp: 0.0 | Decision: Hold | Net: 0\n",
            "Headline: Tesla owners are trading in cars at record rates a... | Sentiment: neutral | Score: 0.00 | dp: 0.0 | Decision: Hold | Net: 0\n",
            "Headline: Rabbi Killed by Traffic After His Tesla Has Veered... | Sentiment: tense | Score: -0.30 | dp: -6.0 | Decision: Sell | Net: -350.00000000000006\n",
            "Headline: Stock market today SP 500 snaps 4week losing strea... | Sentiment: neutral | Score: 0.00 | dp: 0.0 | Decision: Hold | Net: 0\n",
            "Headline: Elon Musk talks up Tesla39s future at employee all... | Sentiment: neutral | Score: 0.30 | dp: 6.0 | Decision: Buy | Net: 350.00000000000006\n",
            "Headline: TSLA 39Light Years39 Ahead of Competition AI Key t... | Sentiment: neutral | Score: 0.30 | dp: 6.0 | Decision: Buy | Net: 350.00000000000006\n",
            "Headline: Trump has suggested sending Tesla TSLA vandals to ... | Sentiment: neutral | Score: 0.00 | dp: 0.0 | Decision: Hold | Net: 0\n",
            "Headline: Googles 32B Deal and a Silicon Valley Spy Scandal ... | Sentiment: shaky | Score: -0.22 | dp: -4.404 | Decision: Sell | Net: -350.00000000000006\n",
            "Headline: Russian journalist target by Kremlinbacked spy rin... | Sentiment: neutral | Score: 0.00 | dp: 0.0 | Decision: Hold | Net: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.read_csv(\"/content/drive/MyDrive/Livewire/stock_lexicon.csv\").head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBIQLND0Bnj7",
        "outputId": "817f5d7f-21b2-44e6-ddd4-8b9d4b3a87b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Item  POS  Sentiment_Score\n",
            "0  's market  NaN        -0.054855\n",
            "1   's trade  NaN        -0.099529\n",
            "2   & market  NaN        -0.077722\n",
            "3    & stock  NaN        -0.064574\n",
            "4    + stock  NaN         0.545200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPROVEMENTS BEGIN HERE"
      ],
      "metadata": {
        "id": "ZZWq_fGyAaRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApJKgy8IAerY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_"
      ],
      "metadata": {
        "id": "ELwvDYCoAgFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZHwRWLF6Afxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g4-F3gzmAfnc"
      }
    }
  ]
}